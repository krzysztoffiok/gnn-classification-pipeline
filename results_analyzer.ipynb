{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "\n",
    "def decode_feature_string(feature_string):\n",
    "    feature_string = feature_string.split(\"[\")[1]\n",
    "    flist = feature_string.split(\"-\")\n",
    "    embedding_method = flist[1]\n",
    "    merge_features = flist[2]\n",
    "    add_degree = flist[3]\n",
    "    compute_node_embeddings = flist[4]\n",
    "    time_series_feature_set = flist[5]\n",
    "    if time_series_feature_set == \"empty\":\n",
    "        time_series_feature_set = \"\"\n",
    "    if add_degree == \"False\":\n",
    "        add_degree = \"\"\n",
    "    elif add_degree == \"True\":\n",
    "        add_degree = \"D\"\n",
    "\n",
    "    if compute_node_embeddings == \"True\":\n",
    "        if merge_features == \"True\":\n",
    "            main_text = f\"{time_series_feature_set}\\n{embedding_method}\"\n",
    "        elif merge_features == \"False\":\n",
    "            main_text = embedding_method\n",
    "    elif compute_node_embeddings == \"False\":\n",
    "        main_text = time_series_feature_set\n",
    "\n",
    "    final_feature_label = f\"{main_text}\\n{add_degree}\"\n",
    "    return final_feature_label\n",
    "\n",
    "\n",
    "def nlargest_and_plot(dftemp, metric, title_ads, save=False, tail=False, file_folder=\"hcp_rs_606_results_vis\"):\n",
    "    metrics_list = ['Accuracy', 'Balanced_accuracy_score', 'F1macro', 'F1micro',\n",
    "       'F1weighted', 'MCC', 'precision', 'recall_score']\n",
    "    dftemp[metrics_list] = dftemp[metrics_list].astype(np.float)\n",
    "    \n",
    "    nsmallest_metric = dftemp[[metric, \"x_names\"]].nsmallest(len(dftemp), metric)\n",
    "    if tail:\n",
    "        nsmallest_metric = nsmallest_metric.tail(tail)\n",
    "    print(nsmallest_metric)\n",
    "    x = nsmallest_metric[\"x_names\"]\n",
    "    y = nsmallest_metric[metric]\n",
    "    fig = plt.figure(figsize=(20,9), dpi=150)\n",
    "    plt.scatter(x, y)\n",
    "    fig.suptitle(f\"{metric}, {title_ads}\")\n",
    "    if save:\n",
    "        try:\n",
    "            os.mkdir(file_folder)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        save_name = f\"./{file_folder}/{metric}_{title_ads}.jpg\"\n",
    "        save_name = save_name.replace(\",\", \"_\")\n",
    "        save_name = save_name.replace(\" \", \"_\")\n",
    "        plt.savefig(save_name)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATASET\n",
    "# file_folder = \"hcp_17_51\"\n",
    "# file_folder = \"mutag\"\n",
    "# file_folder = \"uj_gpu\"\n",
    "file_folder = \"hcp_rs_606\"\n",
    "# file_folder = 'hcp_17_49'\n",
    "# file_folder = \"hcp_17_ex\"\n",
    "\n",
    "file_folder = f\"./training_visualizations/{file_folder}\"\n",
    "    \n",
    "file_list = [f for f in listdir(file_folder) if isfile(join(file_folder, f))]\n",
    "file_list = [f\"{file_folder}/{x}\" for x in file_list]\n",
    "\n",
    "file_ident = \"metric_results\"\n",
    "\n",
    "metric_results_file_list = [x for x in file_list if file_ident in x]\n",
    "\n",
    "\n",
    "# CREATE A SINGLE DF WITH ALL RESULTS\n",
    "dffinal = pd.DataFrame()\n",
    "for file in metric_results_file_list:\n",
    "    df = pd.read_excel(file)\n",
    "    df = df.T\n",
    "    df.columns = df.loc[\"Unnamed: 0\"]\n",
    "    df.drop(\"Unnamed: 0\", axis=0, inplace=True)\n",
    "    df.index = [file.split(\"/\")[-1][len(file_folder.split(\"/\")[-1])+1:-len(file_ident)-6]]\n",
    "    dffinal = pd.concat([dffinal, df], axis=0)\n",
    "    \n",
    "# DECODE VALUES OF PARAMETERS  \n",
    "ifl = 0\n",
    "dffinal[\"Threshold\"] = [f\"{x.split('_')[ifl]}\" for x in dffinal.index.tolist()]\n",
    "if dffinal.index.tolist()[0].find(\"empty\") != -1:\n",
    "    ifl += 1\n",
    "                        \n",
    "dffinal[\"Hidden Channels\"] = [f\"{x.split('_')[ifl+2]}\" for x in dffinal.index.tolist()]\n",
    "\n",
    "dffinal[\"Features\"] = [f\"{decode_feature_string(x)}\" for x in dffinal.index.tolist()]                       \n",
    "dffinal[\"Model\"] = [f\"{x.split('_')[ifl+6]}\" for x in dffinal.index.tolist()]  \n",
    "dffinal[\"Graph type\"] = [f\"{x.split('_')[ifl+8]}\" for x in dffinal.index.tolist()]\n",
    "dffinal[\"Batch size\"] = [f\"{x.split('_')[ifl+9]}\" for x in dffinal.index.tolist()]\n",
    "                    \n",
    "name_cols = [\"Threshold\", \"Hidden Channels\", \"Features\", \"Model\", \"Batch size\", \"Graph type\"]                       \n",
    "dffinal[\"x_names\"] = [\"\\n\".join(dffinal.loc[dffinal.index.tolist(), name_cols].values.tolist()[x]) for x in range(len(dffinal))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name1, group1 in dffinal.groupby(\"Features\"):\n",
    "    for name2, group2 in group1.groupby(\"Model\"):\n",
    "        for name3, group3 in group2.groupby(\"Batch size\"):\n",
    "            print(group3)\n",
    "            # PLOT N BEST MODELS\n",
    "            n_best= 20\n",
    "            metric = \"MCC\"\n",
    "            metrics_list = ['Accuracy', 'Balanced_accuracy_score', 'F1macro', 'F1micro',\n",
    "                   'F1weighted', 'MCC', 'precision', 'recall_score']\n",
    "            group3[metrics_list] = group3[metrics_list].astype(np.float)\n",
    "            local_name1 = name1.replace('\\n', ' ')\n",
    "            nlargest_and_plot(dftemp=group3.nlargest(n_best, metric), metric=metric,\n",
    "                              title_ads=f\"{local_name1, name2, name3}\", save=True,\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to select only a part of the results\n",
    "def show_only(x):\n",
    "#     if x.find(\"_GCNse_\") != -1:\n",
    "    if x.find(\"full\") != -1:\n",
    "            if x.find(\"Feather\") != -1:\n",
    "                return True\n",
    "    else:\n",
    "        return False        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dffinal[dffinal.index.map(lambda x: show_only(x)) == True].sort_values(by=\"MCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PLOT IN GROUPS\n",
    "name_cols = [\"Threshold\", \"Hidden Channels\", \"Features\", \"Model\", \"Batch size\", \"Graph type\"] \n",
    "for col in name_cols:\n",
    "    for name, group in dffinal.groupby(col):\n",
    "        nlargest_and_plot(dftemp=group, metric=\"MCC\", tail=20, save=True, title_ads=f\"grouped by {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT N BEST MODELS\n",
    "n_best= 20\n",
    "metric = \"precision\"\n",
    "metrics_list = ['Accuracy', 'Balanced_accuracy_score', 'F1macro', 'F1micro',\n",
    "       'F1weighted', 'MCC', 'precision', 'recall_score']\n",
    "for metric in metrics_list:\n",
    "    dffinal[metrics_list] = dffinal[metrics_list].astype(np.float)\n",
    "    nlargest_and_plot(dftemp=dffinal.nlargest(n_best, metric), metric=metric, save=True, title_ads=f\"{n_best} best models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r hcp_rs_606_results_vis.zip hcp_rs_606_results_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
